<!DOCTYPE html>
<html lang="en" data-bs-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs | Nhat Nguyen</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
    <style>
        .content-container {
            margin-top: 100px;
            max-width: 800px;
        }
        pre {
            background-color: #1e293b;
            padding: 1rem;
            border-radius: 0.5rem;
            color: #e2e8f0;
        }
    </style>
</head>
<body>

    <div class="container content-container">
        <h1 class="display-4 fw-bold mb-4 text-gradient">Large Language Models (LLMs)</h1>

        <section class="mb-5">
            <h2 class="h3 fw-bold text-accent">1. Overview</h2>
            <p>Large Language Models (LLMs) are AI models designed to understand and generate human language. They are built using transformer architectures and trained on massive datasets.</p>
        </section>

        <section class="mb-5">
            <h2 class="h3 fw-bold text-accent">2. Key Concepts</h2>
            <ul>
                <li><strong>Tokenization:</strong> Breaking text into smaller units (tokens).</li>
                <li><strong>Attention Mechanism:</strong> Allowing the model to focus on different parts of the input sequence.</li>
                <li><strong>Pre-training & Fine-tuning:</strong>
                    <ul>
                        <li><em>Pre-training:</em> Learning general language patterns.</li>
                        <li><em>Fine-tuning:</em> Adapting to specific tasks (e.g., chat, coding).</li>
                    </ul>
                </li>
            </ul>
        </section>

        <section class="mb-5">
            <h2 class="h3 fw-bold text-accent">3. Popular Models</h2>
             <ul>
                <li><strong>GPT-4 (OpenAI):</strong> Proprietary, multimodal.</li>
                <li><strong>Llama 3 (Meta):</strong> Open weights, highly efficient.</li>
                <li><strong>Claude 3 (Anthropic):</strong> Strong reasoning and large context window.</li>
                <li><strong>Gemini (Google):</strong> Multimodal, integrated with Google ecosystem.</li>
            </ul>
        </section>

        <section class="mb-5">
            <h2 class="h3 fw-bold text-accent">4. Prompt Engineering</h2>
            <p>Techniques to guide LLM outputs:</p>
            <ul>
                <li><strong>Zero-shot:</strong> Asking without examples.</li>
                <li><strong>Few-shot:</strong> Providing a few examples of desired output.</li>
                <li><strong>Chain-of-Thought:</strong> Encouraging the model to explain its reasoning.</li>
            </ul>
        </section>

        <section class="mb-5">
            <h2 class="h3 fw-bold text-accent">5. Coding with LLMs (LangChain Example)</h2>
             <pre><code>from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)

print(llm(prompt.format(product="colorful socks")))</code></pre>
        </section>

    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
    <script src="../nav_footer.js"></script>
</body>
</html>
